{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SL - Comparing classifiers - CORRECTION\n",
    "\n",
    "In this hands-on lesson, we will compare the performance of different algorithms for classification on the Iris data set.  \n",
    "\n",
    "This notebook is adapted from https://medium.com/@pinnzonandres/iris-classification-with-svm-on-python-c1b6e833522c \n",
    "\n",
    "and https://www.kaggle.com/tcvieira/simple-random-forest-iris-dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris is a genus of 260â€“300 species of flowering plants with showy flowers. It takes its name from the greek word for a rainbow,Iris.\n",
    "\n",
    "In the dataset we have three types of iris:\n",
    "- Iris Setosa\n",
    "- Iris Versicolour\n",
    "- Iris Virginica\n",
    "\n",
    "For each flower we know (the features of our machine learning classifier):\n",
    "\n",
    "- Sepal length\n",
    "- Sepal width\n",
    "- Petal length\n",
    "- Petal width\n",
    "\n",
    "The goal is to correctly classify the three types of iris using the four features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and inspect them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "#Load dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas for better manipulation\n",
    "import pandas as pd\n",
    "# Transofm the data in a dataframe\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = pd.Series(iris.target)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the size of the data\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some usefull visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Scatterplot the 'petal width' vs all the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.unique(df['target'].values)\n",
    "ncols = 3 \n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=1, figsize=(10,3))\n",
    "feature_y = df.columns[-2]\n",
    "for col in range(ncols):\n",
    "    feature_x = df.columns[col]\n",
    "    ax = axs[col]\n",
    "    for i in targets:\n",
    "        mask = df['target'].values == i\n",
    "        label = iris.target_names[i]\n",
    "\n",
    "        ax.scatter(df[feature_x].values[mask], \n",
    "                   df[feature_y].values[mask],\n",
    "                   label=label)\n",
    "    if col == 0:\n",
    "        ax.set_ylabel(feature_y)\n",
    "    ax.set_xlabel(feature_x)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot something more insigthfull with seaborn\n",
    "sns.set()\n",
    "sns.pairplot(df[['petal length (cm)', 'petal width (cm)', \n",
    "                   'sepal length (cm)', 'sepal width (cm)', 'target']],\n",
    "             hue=\"target\", diag_kind=\"kde\", \n",
    "             palette=['blue','orange','green'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visual inspection it seems that the petals width and length are the two most important features to distinguish the three groups of flowers\n",
    "\n",
    "We can also look at correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.heatmap(df.corr())\n",
    "ax.set_title('Correlation On iris Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that:\n",
    "- the shape of the petals (width and length) are the most correlated with the type of flowers \n",
    "- the sepal length wich also haves a positive but minor correlation\n",
    "- we have the negative correlation of the sepal width column (and correlation is not very high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: prepare the data to apply machine learning classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]  # define the features\n",
    "y = df.iloc[:, -1].values  # define the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple SVM with the 2 most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use sklearn to fit an SVM model.\n",
    "In this simple example we will use the first two feature vectors only and plot the decision boundaries. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "kernel = 'linear'\n",
    "svc1 = svm.SVC(kernel=kernel)\n",
    "svc1.fit(X_train.iloc[:, :2], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "def plot_decision_boundaries(clf, X_train, y_train):                                                                      \n",
    "    cmap_light = ListedColormap([\"orange\", \"cyan\", \"cornflowerblue\"])\n",
    "    cmap_bold = [\"darkorange\", \"c\",  \"darkblue\" ]\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X_train.iloc[:, :2],\n",
    "        cmap=cmap_light,\n",
    "        ax=ax,\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        xlabel=X_train.columns[0],\n",
    "        ylabel=X_train.columns[1],\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "\n",
    "    # Plot also the training points\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x=X_train.iloc[:, 0],\n",
    "        y=X_train.iloc[:, 1],\n",
    "        hue=y_train,\n",
    "        palette=cmap_bold,\n",
    "        alpha=1.0,\n",
    "        edgecolor=\"black\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_decision_boundaries(svc1, X_train, y_train)\n",
    "plt.title(\"3-Class classification SVM Kernel: \" + kernel )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Use the trained model to predict the labels of the test set, and evaluate the prediction (i.e compute the accuracy of the model).\n",
    "- Define a SVM classifier with polynomial kernels of degree 3 and compare its performance with the linear SVM classifier\n",
    "\n",
    "### Question\n",
    "What do you deduce from the results?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svc1.predict(X_test.iloc[:, :2])\n",
    "accuracy = np.sum(prediction == y_test) / y_test.shape[0]\n",
    "print(f'Predicted array: {prediction}')\n",
    "print(f'Test array: {y_test}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kernel = 'poly'\n",
    "degree = 3\n",
    "svc2 = svm.SVC(kernel=kernel, degree=degree)\n",
    "svc2.fit(X_train.iloc[:, :2], y_train)\n",
    "plot_decision_boundaries(svc2, X_train, y_train)\n",
    "plt.title(f\"3-Class classification SVM Kernel:{kernel} Degree: {degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svc2.predict(X_test.iloc[:, :2])\n",
    "accuracy = np.sum(prediction == y_test) / y_test.shape[0]\n",
    "print(f'Predicted array: {prediction}')\n",
    "print(f'Test array: {y_test}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model with all features and compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the SVM model\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "#Fit the model for the data\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Make the prediction\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of accurate predictions\n",
    "sum(y_test == y_pred)\n",
    "#Accuracy\n",
    "print(\"Accuracy:\",sum(y_test == y_pred)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy sk learn:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use cross validation to compute the accuracy of our model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "svm_clf = SVC(kernel = 'linear', random_state = 0)\n",
    "accuracies = cross_val_score(estimator = svm_clf, X = X, y = y, cv = 5)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_feature_imp = pd.Series(abs(classifier.coef_[0]), index=df.columns[:-1]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceating a bar plot\n",
    "svc_feature_imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a better bar plot\n",
    "sns.barplot(x=svc_feature_imp, y=svc_feature_imp.index) \n",
    "\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Try to repeate what done with SVM by using random forest\n",
    "- Vary the depth of your trees and the size of your forest to see how the results vary\n",
    "\n",
    "If you want to get informatio on random forest type `RandomForestClassifier?` in a code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Random Forest Classifier (an istance of the class)\n",
    "clf=RandomForestClassifier(max_depth=3, n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=3, n_estimators=100)\n",
    "accuracies = cross_val_score(estimator = rf_clf, X = X, y = y, cv = 5)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_, index=iris.feature_names).sort_values(ascending=False)\n",
    "feature_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index) \n",
    "\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
